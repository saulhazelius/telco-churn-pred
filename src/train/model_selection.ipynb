{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd65d7f5",
   "metadata": {},
   "source": [
    "### Churn Prediction\n",
    "\n",
    "#### Dataset: Telco: https://www.kaggle.com/datasets/blastchar/telco-customer-churn\n",
    "\n",
    "#### Model selection.\n",
    "\n",
    "From the previous notebook (churn_predicion.ipynb) we saw that logistic regression outperformed random forest using a standard train test splitting and default model parameters. In this notebook we are gonna compare logistic regression with RF, but changing its hyperparameters. The hyperparameters search will be performed employing bayesian optimization and the metrics will be recorded via MLFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bef12f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, space_eval, tpe\n",
    "from hyperopt.pyll.base import scope\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75a06726-b492-4e68-bc7a-81682174d186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    \"\"\"Preprocessing of DataFrame returning cleaned selected variables.\n",
    "    Returns X and y arrays and DictVectorizer.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(\"../data/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "\n",
    "    df.TotalCharges.replace(\" \", np.nan, inplace=True)\n",
    "    df.TotalCharges = df.TotalCharges.astype(float)\n",
    "    df.dropna(inplace=True)\n",
    "    df.Churn = (df.Churn == \"Yes\").astype(int)\n",
    "    sel_vars = [\n",
    "        \"Contract\",\n",
    "        \"OnlineSecurity\",\n",
    "        \"TechSupport\",\n",
    "        \"OnlineBackup\",\n",
    "        \"InternetService\",\n",
    "        \"MonthlyCharges\",\n",
    "        \"TotalCharges\",\n",
    "        \"tenure\",\n",
    "    ]\n",
    "    df_sel = df[sel_vars]\n",
    "    dic_df = df_sel.to_dict(orient=\"records\")\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X = dv.fit_transform(dic_df)  # Returns an np array\n",
    "    y = df.Churn  # Pandas series, anyway the classifier can deal with it\n",
    "\n",
    "    return X, y, dv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f64ca7e6-3265-4403-86a0-3ae5ef02d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, dv = preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef42feec-c2b2-408d-94d6-1529b59e5f87",
   "metadata": {},
   "source": [
    "### Model evaluation strategy:\n",
    "* 25% hold-out set\n",
    "* 75% CV 5-fold for hyperparameters search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18019f14-032e-4a38-ada7-23659f70c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "KF = 5\n",
    "TEST_SIZE = 0.25\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=0, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "245924c8-1c93-401d-9967-b236b5ced5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams for bayes optimization with hyperopt\n",
    "lr_space = {\n",
    "    \"penalty\": hp.choice(\"penalty\", [\"l1\", \"l2\"]),\n",
    "    \"C\": hp.uniform(\"C\", 0, 10),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c83b73ac-30f4-465f-ac5b-17cb79380159",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_space = {\n",
    "    \"max_depth\": scope.int(hp.quniform(\"max_depth\", 3, 18, 1)),\n",
    "    \"n_estimators\": scope.int(hp.quniform(\"n_estimators\", 80, 320, 20)),\n",
    "    \"min_samples_leaf\": scope.int(hp.quniform(\"min_samples_leaf\", 3, 13, 2)),\n",
    "    \"random_state\": scope.int(hp.choice(\"random_state\", [22, 44, 66])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d9466d9-2b7e-45fa-9e5c-d2f3326a14af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lr(space, kf=KF):\n",
    "\n",
    "    clf = LogisticRegression(solver=\"liblinear\", C=space[\"C\"], penalty=space[\"penalty\"])\n",
    "\n",
    "    cv = StratifiedKFold(random_state=22, n_splits=KF, shuffle=True)\n",
    "    score = cross_val_score(\n",
    "        clf, X_train, y_train, cv=cv, scoring=\"accuracy\", n_jobs=-1\n",
    "    ).mean()\n",
    "\n",
    "    loss = -score\n",
    "    print(f\"Accuracy: {score}\")\n",
    "\n",
    "    return {\"loss\": loss, \"params\": space, \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bdf02ad-5361-4a56-b437-f86a03f29192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_rf(space, kf=KF):\n",
    "\n",
    "    clf = RandomForestClassifier(**space)\n",
    "\n",
    "    cv = StratifiedKFold(random_state=22, n_splits=KF, shuffle=True)\n",
    "    score = cross_val_score(\n",
    "        clf, X_train, y_train, cv=cv, scoring=\"accuracy\", n_jobs=-1\n",
    "    ).mean()\n",
    "\n",
    "    loss = -score\n",
    "    print(f\"Accuracy: {score}\")\n",
    "\n",
    "    return {\"loss\": loss, \"params\": space, \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c7b8788-c4d6-492a-9ffc-18d1c037fae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/saul/telco-churn-pred/notebooks/mlruns/1', creation_time=1673813117579, experiment_id='1', last_update_time=1673813117579, lifecycle_stage='active', name='Hyperparams_Search', tags={}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Hyperparams_Search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5643edae-66a8-48ba-aae5-770e5b251f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7935152926787593                          \n",
      "Accuracy: 0.7925661663534088                                                     \n",
      "Accuracy: 0.7925661663534088                                                     \n",
      "Accuracy: 0.7925661663534088                                                     \n",
      "Accuracy: 0.7942735865176218                                                     \n",
      "Accuracy: 0.7944631599773375                                                     \n",
      "Accuracy: 0.7925661663534088                                                     \n",
      "Accuracy: 0.7940840130579062                                                     \n",
      "Accuracy: 0.7925661663534088                                                     \n",
      "Accuracy: 0.7938944395981906                                                     \n",
      "Accuracy: 0.7942737663785893                                                      \n",
      "Accuracy: 0.7925661663534088                                                      \n",
      "100%|██████████| 12/12 [00:04<00:00,  2.93trial/s, best loss: -0.7944631599773375]\n"
     ]
    }
   ],
   "source": [
    "trials_lr = Trials()\n",
    "with mlflow.start_run(run_name=\"hypersearch_lr\") as run:\n",
    "\n",
    "    best = fmin(\n",
    "        fn=objective_lr,\n",
    "        space=lr_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=12,\n",
    "        trials=trials_lr,\n",
    "        rstate=np.random.default_rng(789),\n",
    "    )\n",
    "    best_lr = space_eval(lr_space, best)\n",
    "    mlflow.log_dict(best_lr, \"best_lr_params.json\")\n",
    "    mlflow.log_params(best_lr)\n",
    "    mlflow.log_metric(\"best_acc\", -trials_lr.best_trial[\"result\"][\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17c33fd0-e21a-4083-9a2d-12c38001f798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7918078725145463                          \n",
      "Accuracy: 0.7954106675539807                                                     \n",
      "Accuracy: 0.795409228666241                                                      \n",
      "Accuracy: 0.7944620808115327                                                     \n",
      "Accuracy: 0.7916170400280583                                                     \n",
      "Accuracy: 0.7935142135129545                                                     \n",
      "Accuracy: 0.7916179393328957                                                     \n",
      "Accuracy: 0.7916186587767656                                                     \n",
      "Accuracy: 0.7946521938541506                                                     \n",
      "Accuracy: 0.7938928208494833                                                     \n",
      "Accuracy: 0.7944615412286302                                                      \n",
      "Accuracy: 0.7938933604323858                                                      \n",
      "100%|██████████| 12/12 [00:31<00:00,  2.66s/trial, best loss: -0.7954106675539807]\n"
     ]
    }
   ],
   "source": [
    "trials_rf = Trials()\n",
    "with mlflow.start_run(run_name=\"hypersearch_rf\") as run:\n",
    "\n",
    "    best = fmin(\n",
    "        fn=objective_rf,\n",
    "        space=rf_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=12,\n",
    "        trials=trials_rf,\n",
    "        rstate=np.random.default_rng(789),\n",
    "    )\n",
    "    best_rf = space_eval(rf_space, best)\n",
    "    mlflow.log_dict(best_rf, \"best_rf_params.json\")\n",
    "    mlflow.log_params(best_rf)\n",
    "    mlflow.log_metric(\"best_acc\", -trials_rf.best_trial[\"result\"][\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7207b4f-0276-4f44-80ef-f04469b1586f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7944631599773375"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best accuracy Log Reg:\n",
    "-trials_lr.best_trial[\"result\"][\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c02507a-ec09-485b-8383-820b2a8a89b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7954106675539807"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best accuracy RF:\n",
    "-trials_rf.best_trial[\"result\"][\"loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89575f6c-94e2-47f5-87db-a1548c434ba5",
   "metadata": {},
   "source": [
    "#### Metrics with the hold-out set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ef02cf-c341-4ad1-ada0-64766ef8b793",
   "metadata": {},
   "source": [
    "#### Log reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77be5361-7139-414e-a8d5-456c6ba5553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(**best_lr, solver=\"liblinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53667e97-2da4-48d1-9835-de0ba094603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"log_reg_hold_out\"):\n",
    "\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    acc = accuracy_score(y_pred, y_test)\n",
    "    f1 = f1_score(y_pred, y_test)\n",
    "    rocauc = roc_auc_score(y_pred, y_test)\n",
    "    mlflow.log_metric(\"acc_holdout\", acc)\n",
    "    mlflow.log_metric(\"f1_holdout\", f1)\n",
    "    mlflow.log_metric(\"roc_auc_holdout\", rocauc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6ab5ea-027a-41e8-9751-775e071a5545",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37980bf9-d4b6-4977-bee1-e57b9df4a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(**best_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3126937-1ad4-407b-8589-f08b44b8cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"rf_hold_out\"):\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    acc = accuracy_score(y_pred, y_test)\n",
    "    f1 = f1_score(y_pred, y_test)\n",
    "    rocauc = roc_auc_score(y_pred, y_test)\n",
    "    mlflow.log_metric(\"acc_holdout\", acc)\n",
    "    mlflow.log_metric(\"f1_holdout\", f1)\n",
    "    mlflow.log_metric(\"roc_auc_holdout\", rocauc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f36985-80e5-4074-b14d-27704b20c526",
   "metadata": {},
   "source": [
    "### Model selected:\n",
    "#### Logistic Regression\n",
    "Log model artifacts:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf49fe12-957e-47e6-ade7-995a3dedde59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/churn_artifacts.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump((dv, lr), \"../model/churn_artifacts.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35f3d0b3-3670-4c0a-a27f-8040e2f46aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow.log_artifacts(\"../model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
